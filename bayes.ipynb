{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 贝叶斯"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 概念"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "贝叶斯定理：在B出现的前提下，A出现的概率等于A和B同时出现的概率除以B出现的概率。公式如下:  \n",
    "$$ P(A|B) = \\frac{P(A)P(B|A)}{P(B) }$$  \n",
    "\n",
    "影响A的因素往往不止一个，即$B(b_1,b_2,b_3...)$。假设每个条件b互相独立，就是朴素贝叶斯"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 原理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "贝叶斯用于分类，将A类比于类别C，B类比于特征F，则有:  \n",
    "$$P(C|F_1,F_2,...F_n) = \\frac{P(C)P(F_1,F_2..F_n|C)}{P(F_1,F_2..F_n)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在上式中，P(C) 可以根据概率得出，$P(F_1,F_2,...F_n)是一个定值$,不确定的为$P(F_1,F_2...F_n|C)$  \n",
    "由于$b_1,b_2...b_n$ 互相独立，根据链式法则得：  \n",
    "$P(F_1,F_2...F_n|C) = P(F_1|C)P(F_2|C)...P(F_n|C) = \\prod_{i=1}^{n}{} P(F_i|C)$   \n",
    "因为分类往往也不止一个，$C = (C_1,C_2....C_k)$, 设$P(F_1,F_2,...F_n)=Z$,则：  \n",
    "$P(C_j|F_1,F_2...F_n) = \\frac{1}{Z}P(C)\\prod_{i=1}^{n}{}P(F_i|C_j)$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据上述公式，假设对于样本s，有n个特征值，k个分类结果。提取样本的n个特征值$F_1,F_2...F_n$代入上式进行k次运算，  \n",
    "得到$C_1,C_2...C_k$的预测值，选择概率最大的那个即为分类结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以我们现在的问题就变成了求$P(F_i|C)$的问题。这是一个条件概率的参数估计问题。我们假设:  \n",
    "$P(F_i|C)$符合某种分布，如高斯分布，那么$P(F_i|C) =\\frac{1}{\\sqrt{2π}σ}e^{-\\frac{(F_i-u)^2}{2σ^2}} (m_c为C类的样本数) $  \n",
    "$P(F_i|C)被参数θ_{c,i} 唯一指定$,若是高斯分布，则$θ_{c,i} = (u_{c,i},σ_{c,i}^2)$\n",
    "我们的样本集合中的每个样本都符合上两条。  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$设C类集合为D_c,样本个数为m_c,x_i 表示第i个特征值，x^{(j)}表示第j个样本。 $  \n",
    "$则参数θ𝑐,𝑖的似然函数L(θ_{c,i}) ,表示为m_c个样本(X_1,X_2 ....X_{m_c}在第i个特征上的联合概率分布:$  \n",
    "$ L(θ_{c,i}) = \\prod_{i=1}^{m_c}P(x_i|C)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们的目的就是要$L(θ_{c,i}) $最大。为了方便计算，对两边取对数得:  \n",
    "$ LL(L(θ_{c,i}) = \\sum_{i=1}^{m_c}log(P(x_i|C))$  \n",
    "\n",
    "然后使用极大似然估计求解$θ_{c,i}$  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以正态分布为例:  \n",
    "$ LL(θ_{c,i}) = \\sum_{i=1}^{m_c}log(P(x_i|C))=\\sum_{j=1}^{m_c}log(\\frac{1}{\\sqrt{2π}σ}e^{-\\frac{(x_i^{(j)}-u)^2}{2σ^2}})$  \n",
    "    $=LL(u_{c,i},σ_{c,i}^2) = -\\frac{m_c}{2}log(2π)-\\frac{m_c}{2}log(σ_{c,i}^2)-\\frac{1}{2σ_{c,i}^2}\\sum_{i=1}^{m_c}{}(x_i-u_{c,i})^2$    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后对u和σ^2分别取偏导，并令偏导为0，得：  \n",
    "$$u_{c,i} = \\frac{1}{m_c}\\sum_{j=1}^{m_c}{} x_i^{(j)} = \\overline{x_i}$$  \n",
    "$$ σ_{c,i}^2 = \\frac{1}{m_c}\\sum_{i=1}^{n}{}(x_i^{(j)}-\\overline{x_i})^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用iris数据集，来实现一下"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils import calc_accuracy_class\n",
    "from utils import fl_score\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = datasets.load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X的大小为：(120, 4)\n",
      "tain_y的大小为：(120,)\n",
      "test_X的大小为：(30, 4)\n",
      "test_y的大小为：(30,)\n"
     ]
    }
   ],
   "source": [
    "#将数据分为训练集和测试集\n",
    "train_X,test_X,train_y,test_y = train_test_split(X,y,test_size = 0.20,random_state = 1)\n",
    "print(f\"train_X的大小为：{train_X.shape}\")\n",
    "print(f\"tain_y的大小为：{train_y.shape}\")\n",
    "print(f\"test_X的大小为：{test_X.shape}\")\n",
    "print(f\"test_y的大小为：{test_y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 先使用sklearn看效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== 训练集 ====== \n",
      "0 类的fl_score 为:1.0\n",
      "1 类的fl_score 为:0.918918918918919\n",
      "2 类的fl_score 为:0.9318181818181818\n",
      "===== 测试集 ===== \n",
      "0 类的fl_score 为:1.0\n",
      "1 类的fl_score 为:0.9600000000000001\n",
      "2 类的fl_score 为:0.923076923076923\n"
     ]
    }
   ],
   "source": [
    "skmodel = GaussianNB()\n",
    "skmodel.fit(train_X,train_y)\n",
    "\n",
    "#预测\n",
    "print(\"==== 训练集 ====== \")\n",
    "pred_y = skmodel.predict(train_X)\n",
    "fl_score(pred_y,train_y)\n",
    "\n",
    "print(\"===== 测试集 ===== \")\n",
    "pred_y = skmodel.predict(test_X)\n",
    "fl_score(pred_y,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(n_x,n_c):\n",
    "    '''\n",
    "    Function:\n",
    "    初始化theta\n",
    "    Arguments:\n",
    "    n_x -- 特征个数\n",
    "    n_c -- 分类个数\n",
    "    '''\n",
    "    theta = np.random.randn(n_c,n_x)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由贝叶斯的似然函数可知道，假设k个类C，特征值X有n个，则theta矩阵为 k*n或n*k  \n",
    "因为为高斯分布，所以每一个theta有两个参数值 $μ和σ^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(train_X,train_y):\n",
    "    '''\n",
    "    train_X -- shape is:(m,n)\n",
    "    train_y -- shape is (m,)\n",
    "    '''\n",
    "    m,n_x = train_X.shape\n",
    "    classes = set(train_y)\n",
    "    n_c = len(classes)\n",
    "    \n",
    "    #初始化参数\n",
    "    pc_map={}\n",
    "    theta_map = {}\n",
    "    for c in classes:\n",
    "        #计算每个类的概率P(C)\n",
    "        m_c = np.sum(train_y == c)\n",
    "        pc = m_c/m\n",
    "        pc_map[c] = pc\n",
    "        \n",
    "        \n",
    "        #取子集\n",
    "        sub_rows = np.where(train_y == c)\n",
    "        sub_X = train_X[sub_rows]\n",
    "    \n",
    "        \n",
    "        #求每个特征在c分类上的平均值\n",
    "        \n",
    "        mean = np.sum(sub_X,axis=0)/m_c  #shape is (1,n_x)\n",
    "        mean = mean.reshape(1,-1)\n",
    "        # 求每个特征在c分类上的sigma^2\n",
    "        sigma = np.sum(np.square(sub_X - mean), axis=0)/m_c  # shape is (1,n_x)\n",
    "        sigma = sigma.reshape(1,-1)\n",
    "        theta_map[c] = (mean,sigma)\n",
    "        \n",
    "    return pc_map,theta_map\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1/Z 为常数，可以不参与计算。因为对数的单调性与原函数单调性是一致的，所以这里计算对数概率，将连乘变成累加，方便计算。\n",
    "所以，$log(P(C|x_1,x_2..x_n)) = log(P(C))\\sum_{i=1}^{n}{}log(P(x_i|C))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cacl_simplelog_prob(X,pc,theta):\n",
    "    '''\n",
    "    Function:\n",
    "        计算某一个C类在特征值上的简化对数概率\n",
    "    Arguments:\n",
    "        X-- shape is (m,n_x)\n",
    "        pc -- 常量，C类的概率\n",
    "        theta -- C类的概率分布参数\n",
    "    Return:\n",
    "        X 在C类上的简化对数概率\n",
    "    '''\n",
    "    mean,sigma = theta\n",
    "    sqrt_sigma = np.sqrt(sigma)\n",
    "    part1 = np.log(np.sum(1/(np.sqrt(2*np.pi)*sqrt_sigma),axis=1))\n",
    "    part2 = -np.sum(np.square(X-mean)/(2*sigma),axis=1)\n",
    "    return pc *(part1+part2) #shape is (m,1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X,pc_map,theta_map):\n",
    "    classes = pc_map.keys()\n",
    "    m,n_x = X.shape\n",
    "    results = np.zeros((m,1))\n",
    "    prob_pd = pd.DataFrame(results,columns=[\"result\"])\n",
    "    for c in classes:\n",
    "        pc = pc_map[c]\n",
    "        theta = theta_map[c]\n",
    "        \n",
    "        prob = cacl_simplelog_prob(X,pc,theta)\n",
    "        prob_pd[c] = prob\n",
    "    max_index = np.argmax(np.array(prob_pd.drop(columns=\"result\")),axis=1)\n",
    "    pred_result  = np.array(prob_pd.drop(columns=\"result\").columns)[max_index]\n",
    "    prob_pd[\"result\"] = pred_result.T\n",
    "    return pred_result        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_map,theta_map = model(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===训练集验证====\n",
      "0 类的fl_score 为:1.0\n",
      "1 类的fl_score 为:0.918918918918919\n",
      "2 类的fl_score 为:0.9318181818181818\n"
     ]
    }
   ],
   "source": [
    "print(\"===训练集验证====\")\n",
    "pred_y = predict(train_X,pc_map,theta_map)\n",
    "fl_score(pred_y,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 类的fl_score 为:1.0\n",
      "1 类的fl_score 为:0.9600000000000001\n",
      "2 类的fl_score 为:0.923076923076923\n"
     ]
    }
   ],
   "source": [
    "print(\"===测试集测试 ====\")\n",
    "pred_y = predict(test_X,pc_map,theta_map)\n",
    "fl_score(pred_y,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
