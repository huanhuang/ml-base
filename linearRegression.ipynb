{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 线性回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用波士顿房价数据集，使用线性回归来预测房价。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 说明"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "线性回归，即学习一个线性方程来拟合特征X与结果Y。  \n",
    "如根据房屋面积x1，房间数量x2，地理位置x3等来预测房屋的价格y。  \n",
    "所以我们要学习一个方程:  \n",
    "$y=w_1x_1+w_2x_2+w_3x_3 + b$  \n",
    "这个方程就是线性回归的$模型函数$，就是最终我们用来预测y值的函数  \n",
    "其中$w_1,w_2,w_3,b$ 就是我们要学习的参数。\n",
    "\n",
    "如何学习$w_1,w_2,w_3,b$ 呢，我们要学到怎样的$w_1,w_2,w_3,b$才能证明这个模型ok呢？  \n",
    "我们的目标是让预测值尽可能地接近真实值。设预测值为$y'$,真实值为y，我们当然是希望|y-$y'$|的值越小越好。  \n",
    "所以我们引入一个代价函数，用来衡量整体的预测值与真实值的整体差距。代价函数如下:  \n",
    "J(W,b) = $\\frac{1}{2m}\\sum_{i=1}^{m}{} (y'^{(i)}-y^{(i)})^2=\\frac{1}{2m}\\sum_{i=1}^{m}{} (W·X^{(i)}+b-y^{(i)})^2$\n",
    "\n",
    "我们的目标就是要最小化J(W,b)。最小化J(W,b)的方法就是梯度下降法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 变量说明"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对所用到的变量做一个统一说明，方便检查。  \n",
    "\n",
    "将$y=w_1x_1+w_2x_2+w_3x_3 + b$  改写为:  \n",
    "   $y=w_0x_0+w_1x_1+w_2x_2+w_3x_3$    \n",
    "   \n",
    "设:  \n",
    "m: 样本个数  \n",
    "n_x：特征维度  \n",
    "θ：($w_0,w_1,w_2,w_3 ...)$  \n",
    "则：  \n",
    "X的shape 为:(m,n_x+1)  \n",
    "y的shape为：(m,1)  \n",
    "θ 的shape = (n_x+1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = datasets.load_boston(return_X_y=True)\n",
    "y = y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X的大小为：(430, 13)\n",
      "tain_y的大小为：(430, 1)\n",
      "test_X的大小为：(76, 13)\n",
      "test_y的大小为：(76, 1)\n"
     ]
    }
   ],
   "source": [
    "#将数据分为训练集和测试集\n",
    "train_X,test_X,train_y,test_y = train_test_split(X,y,test_size = 0.15,random_state = 1)\n",
    "print(f\"train_X的大小为：{train_X.shape}\")\n",
    "print(f\"tain_y的大小为：{train_y.shape}\")\n",
    "print(f\"test_X的大小为：{test_X.shape}\")\n",
    "print(f\"test_y的大小为：{test_y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#标准化\n",
    "def nomalize(X,axis):\n",
    "    mean = np.mean(X,axis)\n",
    "    std = np.std(X,axis)\n",
    "    print(mean.shape)\n",
    "    return (X-mean)/std, mean,std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13,)\n",
      "(430, 14)\n",
      "(76, 14)\n"
     ]
    }
   ],
   "source": [
    "#将数据标准化\n",
    "train_X,mean,std = nomalize(train_X,axis=0)\n",
    "test_X = (test_X-mean)/std\n",
    "\n",
    "#插入一列全为1的表示x0\n",
    "train_X = np.insert(train_X,0,1,axis=1)\n",
    "test_X = np.insert(test_X,0,1,axis=1)\n",
    "print(train_X.shape)\n",
    "print(test_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_parameters(n):\n",
    "    theta = np.random.randn(n,1)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(y_,y):\n",
    "    m = y.shape[0]\n",
    "    cost = np.sum(np.square(y_-y))/(2*m)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 梯度下降"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "损失函数J(·)是一个凸函数。存在极小值。  \n",
    "梯度下降所做的就是在损失函数上沿着导数方向下降，从而靠近极小值。  \n",
    "所以实现梯度下降的步骤为:  \n",
    "1.对θ求偏导:  \n",
    "    $d_θ = \\frac{d_{J(θ)}}{d_θ} = \\frac{1}{m}X.T·(X·θ-y)$  \n",
    "2.根据$d_θ$更新θ的值:   \n",
    "$θ = θ-αd_θ$  \n",
    "α为学习速率，人为指定。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_desent(X,y,theta,learning_rate):\n",
    "    m = y.shape[0]\n",
    "    y_ = np.dot(X,theta)\n",
    "    d_theta = np.dot(X.T,y_-y)/m\n",
    "    theta = theta - learning_rate*d_theta\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测\n",
    "使用模型函数进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X,theta):\n",
    "    return  np.dot(X,theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer(train_X,train_y,theta,learning_rate,steps):\n",
    "    costs = []\n",
    "    for step in range(steps):\n",
    "        theta = gradient_desent(train_X,train_y,theta,learning_rate)\n",
    "        y_ = predict(train_X,theta)\n",
    "        loss = compute_cost(y_,train_y)\n",
    "        costs.append(loss)\n",
    "        if step % 100 == 0:\n",
    "            print(f\"\\nAfter {step} step(s),cost is :{loss}\")\n",
    "    return theta,costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算正确率\n",
    "给定一个误差范围，如果预测值与真实值之差在该范围内，则表示预测准确"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(y_pred,y,error_ratio):   \n",
    "    '''\n",
    "    y_pred---预测值\n",
    "    y -- 真实值\n",
    "    error_ratio ---误差范围，相比于真实值的百分比，如0.1，0.05\n",
    "    '''\n",
    "    y = y.reshape(-1,1)\n",
    "    m = y.shape[0]\n",
    "    correct_num = np.sum(np.fabs(y_pred-y) < error_ratio*y)\n",
    "    return correct_num/m\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 组合到一起，训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(train_X,train_y,test_X,test_y,learning_rate=0.05,steps=1):\n",
    "    m,n_x = train_X.shape\n",
    "    print(learning_rate)\n",
    "    #初始化参数\n",
    "    theta = init_parameters(n_x)\n",
    "    theta,costs = optimizer(train_X,train_y,theta,learning_rate,steps)\n",
    "    \n",
    "    error_ratio = 0.30 # 即误差不能超过30%\n",
    "    print(\"==== 训练集验证 ====\")\n",
    "    y_pred = predict(train_X,theta)\n",
    "    corr_ratio = calc_accuracy(y_pred,train_y,error_ratio)\n",
    "    print(f\"训练集的正确率为：{corr_ratio}\")\n",
    "    \n",
    "    print(\"==== 验证集验证 ====\")\n",
    "    y_pred = predict(test_X,theta)\n",
    "    corr_ratio = calc_accuracy(y_pred,test_y,error_ratio)\n",
    "    print(f\"验证集的正确率为：{corr_ratio}\")\n",
    "    cost = compute_cost(y_pred,test_y)\n",
    "    print(f\"验证集的损失为：{cost}\")\n",
    "\n",
    "    # 绘制损失函数\n",
    "    plt.xlim(0,steps)\n",
    "    plt.plot(costs)\n",
    "    plt.xlabel(\"step(s)\")\n",
    "    plt.ylabel(\"costs\")\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05\n",
      "\n",
      "After 0 step(s),cost is :276.2738498304797\n",
      "\n",
      "After 100 step(s),cost is :11.383861879550937\n",
      "\n",
      "After 200 step(s),cost is :11.105526649397387\n",
      "\n",
      "After 300 step(s),cost is :11.044853898911777\n",
      "\n",
      "After 400 step(s),cost is :11.024364141639044\n",
      "\n",
      "After 500 step(s),cost is :11.015287140476305\n",
      "\n",
      "After 600 step(s),cost is :11.010711278193963\n",
      "\n",
      "After 700 step(s),cost is :11.008289831656361\n",
      "==== 训练集验证 ====\n",
      "训练集的正确率为：0.872093023255814\n",
      "==== 验证集验证 ====\n",
      "验证集的正确率为：0.8289473684210527\n",
      "验证集的损失为：10.975317367624388\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model(train_X,train_y,test_X,test_y,learning_rate=0.05,steps=800)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "253px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
